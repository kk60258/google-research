export PATH_TO_BE_CONFIGURED=/tempssd/people_detection2/model_062217_viveland_v2_gpu_sigmoid_no_freeze_5k_vv4
export CONFIG_FILE=${PATH_TO_BE_CONFIGURED}/no_freeze_5k_vv4.config
export CHECKPOINT_PATH=${PATH_TO_BE_CONFIGURED}/model.ckpt-5000
export OUTPUT_DIR=${PATH_TO_BE_CONFIGURED}/tflite

python3 object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path=$CONFIG_FILE \
--trained_checkpoint_prefix=$CHECKPOINT_PATH \
--output_directory=$OUTPUT_DIR \
--add_postprocessing_op=true

tflite_convert --output_file=$OUTPUT_DIR/detect-102110.tflite  \
 --graph_def_file=$OUTPUT_DIR/tflite_graph.pb \
 --input_arrays=normalized_input_image_tensor \
 --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
 --input_shapes=1,300,300,3 --allow_custom_ops \
 --inference_type=QUANTIZED_UINT8 \
 --mean_values=128 --std_dev_values=128 --change_concat_input_ranges=false

tflite_convert --output_file=$OUTPUT_DIR/012218_with_nms_detections100.tflite  \
 --graph_def_file=$OUTPUT_DIR/tflite_graph.pb \
 --input_arrays=normalized_input_image_tensor \
 --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
 --input_shapes=1,300,300,3 --allow_custom_ops

##no nms 
python3 object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path=$CONFIG_FILE \
--trained_checkpoint_prefix=$CHECKPOINT_PATH \
--output_directory=$OUTPUT_DIR \
--add_postprocessing_op=false
tflite_convert --output_file=$OUTPUT_DIR/031215_iwamura_no_nms.tflite  \
 --graph_def_file=$OUTPUT_DIR/tflite_graph.pb \
 --input_arrays=normalized_input_image_tensor \
 --output_arrays='raw_outputs/box_encodings','raw_outputs/class_predictions','anchors' \
 --input_shapes=1,300,300,3 --allow_custom_ops
           
python3 object_detection/export_inference_graph.py \
--input_type=image_tensor \
--pipeline_config_path=$CONFIG_FILE \
--trained_checkpoint_prefix=$CHECKPOINT_PATH \
--output_directory=${PATH_TO_BE_CONFIGURED}/snpe

snpe-tensorflow-to-dlc \
--input_network /tempssd/people_detection2/mobiledet/model_031215_300x300_person_ciou_oid_iwamura/snpe/frozen_inference_graph.pb \
--input_dim Preprocessor/map/TensorArrayStack/TensorArrayGatherV3 1,300,300,3 \
--out_node detection_classes \
--out_node detection_boxes \
--out_node detection_scores \
--out_node num_detections \
--output_path 031215_300x300_iwamura.dlc \
--allow_unconsumed_nodes \
--debug 0

snpe-tensorflow-to-dlc \
--input_network /tempssd/people_detection2/model_mobiledet_bifpn_0326_11test/snpe/frozen_inference_graph.pb \
--input_dim Preprocessor/map/TensorArrayStack/TensorArrayGatherV3 1,300,300,3 \
--out_node detection_classes \
--out_node detection_boxes \
--out_node detection_scores \
--out_node num_detections \
--output_path 0326_bifpn_300_3-8-0-fastattention.dlc --debug 0

python3 /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools/optimize_for_inference.py \
--input=/tempssd/people_detection2/mobiledet/model_012218_300x300_person_ciou_oid/snpe/frozen_inference_graph.pb \
--output=/tempssd/people_detection2/mobiledet/model_012218_300x300_person_ciou_oid/snpe/frozen_inference_graph_opt.pb \
--input_names=Preprocessor/map/TensorArrayStack/TensorArrayGatherV3 \
--output_names=detection_multiclass_scores,detection_scores,num_detections,raw_detection_scores,raw_detection_boxes,detection_classes,detection_boxes
